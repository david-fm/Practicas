{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import TextVectorization, Embedding\n",
    "from keras_nlp.layers import TransformerEncoder\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "PATH = \"/Users/davidflorezmazuera/Library/CloudStorage/GoogleDrive-270191@student.pwr.edu.pl/Mi unidad/Spanish_V2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_path = os.path.join(PATH, \"authors-genre.csv\")\n",
    "\n",
    "dataframe = pd.read_csv(authors_path, usecols=[1,3], sep=\";\")\n",
    "dataframe = dataframe.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading books from path\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:00<00:00, 214209.10it/s]\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(os.path.dirname(os.path.abspath('')))\n",
    "from web_scrapping.script import Book, Library\n",
    "\n",
    "path = os.path.join(PATH, \"metadata_cleaned.json\")\n",
    "library = Library.from_books_path(path)\n",
    "\n",
    "def get_words_from_metadata(library: Library, book_id: str):\n",
    "    '''\n",
    "        Input: library - Library object\n",
    "               book_id - id of the book\n",
    "               Output: words - int'''\n",
    "    id_in_metadata = book_id.split('_')[0]\n",
    "    # each book in metadata_cleaned.json has an id that is the same that id_in_metadata \n",
    "    books = library.search('book_id', id_in_metadata)\n",
    "    return books[0].words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  book_id gender   words\n",
      "0     0_0   male  108712\n",
      "1     1_0   male   10160\n",
      "2     2_0   male    9046\n",
      "3     3_0   male   10955\n",
      "4     4_0   male   16000\n"
     ]
    }
   ],
   "source": [
    "dataframe['words'] = dataframe['book_id'].apply(lambda book_id: get_words_from_metadata(library, book_id))\n",
    "print(dataframe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe to get only the books that have more than 100 words\n",
    "dataframe = dataframe[dataframe['words'].apply(lambda words: words > 100)]\n",
    "# Subsampling to get same number of females and males\n",
    "\n",
    "female_dataframe = dataframe[dataframe['gender']=='female']\n",
    "male_dataframe = dataframe[dataframe['gender']=='male']\n",
    "number_of_females = female_dataframe['book_id'].count()\n",
    "male_dataframe = male_dataframe.sample(n=number_of_females, random_state=1)\n",
    "\n",
    "mixed_df = pd.concat((female_dataframe,male_dataframe))\n",
    "dataframe = mixed_df\n",
    "dataframe = dataframe.sample(frac=1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = []\n",
    "for book_id in dataframe['book_id']:\n",
    "    # get the .txt file\n",
    "    path = os.path.join(PATH, f\"{book_id}.txt\")\n",
    "    with open(path) as f:\n",
    "        books.append(f.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at jplu/tf-xlm-roberta-base were not used when initializing TFXLMRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFXLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFXLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFXLMRobertaModel were initialized from the model checkpoint at jplu/tf-xlm-roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFXLMRobertaModel\n",
    "model = TFXLMRobertaModel.from_pretrained(\"jplu/tf-xlm-roberta-base\")\n",
    "#tokenizer = XLMRobertaTokenizer.from_pretrained(\"jplu/tf-xlm-roberta-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import XLMRobertaTokenizer\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained(\"xlm-roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(22, 512), dtype=int32, numpy=\n",
       "array([[     0,  33172, 109113, ...,     90,      4,      2],\n",
       "       [     0,   3994,    618, ...,    110,     40,      2],\n",
       "       [     0,  14467,    141, ...,    441,    320,      2],\n",
       "       ...,\n",
       "       [     0,    241,    339, ...,    458,    272,      2],\n",
       "       [     0,    572,     62, ...,     10,    876,      2],\n",
       "       [     0,  70661,  44060, ...,  53317,     12,      2]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(22, 512), dtype=int32, numpy=\n",
       "array([[1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1]], dtype=int32)>}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(books, return_tensors=\"tf\", padding=True, truncation=True, max_length=512)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_y = dataframe['gender'].values\n",
    "\n",
    "# Transform female to 0 and male to 1\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(pre_y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detaset\n",
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=dict(inputs) #Create a tensorflow dataset\n",
    "#train test split, we use 10% of the data for validation\n",
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(22, 512), dtype=int32, numpy=\n",
       "array([[     0,  33172, 109113, ...,     90,      4,      2],\n",
       "       [     0,   3994,    618, ...,    110,     40,      2],\n",
       "       [     0,  14467,    141, ...,    441,    320,      2],\n",
       "       ...,\n",
       "       [     0,    241,    339, ...,    458,    272,      2],\n",
       "       [     0,    572,     62, ...,     10,    876,      2],\n",
       "       [     0,  70661,  44060, ...,  53317,     12,      2]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(22, 512), dtype=int32, numpy=\n",
       "array([[1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1]], dtype=int32)>}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices((dataset, y))\n",
    "ds = ds.shuffle(1000).batch(32).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tfxlm_roberta_model/roberta/pooler/dense/kernel:0', 'tfxlm_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tfxlm_roberta_model/roberta/pooler/dense/kernel:0', 'tfxlm_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert' defined at (most recent call last):\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n      app.start()\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 619, in start\n      self.io_loop.start()\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/tornado/ioloop.py\", line 688, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n      ret = callback()\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/tornado/gen.py\", line 814, in inner\n      self.ctx_run(self.run)\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/tornado/gen.py\", line 775, in run\n      yielded = self.gen.send(value)\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 358, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 536, in execute_request\n      self.do_execute(\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-17-2c10428570f9>\", line 5, in <cell line: 5>\n      history = model.fit(\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/keras/engine/training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/keras/engine/training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/keras/engine/training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/keras/engine/training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/transformers/modeling_tf_utils.py\", line 1554, in train_step\n      loss = self.compiled_loss(y, y_pred, sample_weight, regularization_losses=self.losses)\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/keras/losses.py\", line 152, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/keras/losses.py\", line 272, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/keras/losses.py\", line 2084, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/keras/backend.py\", line 5630, in sparse_categorical_crossentropy\n      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert'\nassertion failed: [Condition x == y did not hold element-wise:] [x (sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/Shape_1:0) = ] [22 1] [y (sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/strided_slice:0) = ] [22 512]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert}}]] [Op:__inference_train_function_47619]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/Users/davidflorezmazuera/Library/CloudStorage/OneDrive-UNIVERSIDADDEMURCIA/PEPERASMUS/Practicas/text_analysis/transformer.ipynb Celda 16\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/davidflorezmazuera/Library/CloudStorage/OneDrive-UNIVERSIDADDEMURCIA/PEPERASMUS/Practicas/text_analysis/transformer.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/davidflorezmazuera/Library/CloudStorage/OneDrive-UNIVERSIDADDEMURCIA/PEPERASMUS/Practicas/text_analysis/transformer.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     optimizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m5e-5\u001b[39m),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/davidflorezmazuera/Library/CloudStorage/OneDrive-UNIVERSIDADDEMURCIA/PEPERASMUS/Practicas/text_analysis/transformer.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     loss\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mSparseCategoricalCrossentropy(from_logits\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/davidflorezmazuera/Library/CloudStorage/OneDrive-UNIVERSIDADDEMURCIA/PEPERASMUS/Practicas/text_analysis/transformer.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m )\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/davidflorezmazuera/Library/CloudStorage/OneDrive-UNIVERSIDADDEMURCIA/PEPERASMUS/Practicas/text_analysis/transformer.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/davidflorezmazuera/Library/CloudStorage/OneDrive-UNIVERSIDADDEMURCIA/PEPERASMUS/Practicas/text_analysis/transformer.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     ds\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/davidflorezmazuera/Library/CloudStorage/OneDrive-UNIVERSIDADDEMURCIA/PEPERASMUS/Practicas/text_analysis/transformer.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert' defined at (most recent call last):\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n      app.start()\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 619, in start\n      self.io_loop.start()\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/tornado/ioloop.py\", line 688, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n      ret = callback()\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/tornado/gen.py\", line 814, in inner\n      self.ctx_run(self.run)\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/tornado/gen.py\", line 775, in run\n      yielded = self.gen.send(value)\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 358, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 536, in execute_request\n      self.do_execute(\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-17-2c10428570f9>\", line 5, in <cell line: 5>\n      history = model.fit(\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/keras/engine/training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/keras/engine/training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/keras/engine/training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/keras/engine/training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/transformers/modeling_tf_utils.py\", line 1554, in train_step\n      loss = self.compiled_loss(y, y_pred, sample_weight, regularization_losses=self.losses)\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/keras/losses.py\", line 152, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/keras/losses.py\", line 272, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/keras/losses.py\", line 2084, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/keras/backend.py\", line 5630, in sparse_categorical_crossentropy\n      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert'\nassertion failed: [Condition x == y did not hold element-wise:] [x (sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/Shape_1:0) = ] [22 1] [y (sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/strided_slice:0) = ] [22 512]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert}}]] [Op:__inference_train_function_47619]"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    ")\n",
    "history = model.fit(\n",
    "    ds,\n",
    "    batch_size=32,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
